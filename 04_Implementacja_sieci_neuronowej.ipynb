{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "04-Implementacja-sieci-neuronowej.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMRyIZZo_sv9",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "*   Dane wejściowe: każda próbka będzie miała 2 wartości $X = [x_1,   x_2]$, wymiary: 1x2\n",
        "*   Mamy 2 neurony w warstwie ukrytej (1x2), wagi tworzą macierz 2x2\n",
        "*   Problem klasyfikacji,output to będzie $y_{pred} = X * W_1 * W_2$, czyli X - macierz wejściowa, W1 - macierz wag idąca do warstwy ukrytej, W2 - macierz wag idąca do warstwy wyjściowej, wynik to nasza predykcja\n",
        "*   Im więcej neuronów w ukrytej warstwie, tym więcej nasza sieć jest się w stanie nauczyć + może się przeuczyć (overfitting do danych wejściowych - wytrenowany model dobrze radzi sobie z danymi, na których był trenowany i znacznie gorzej na nowych danych, których model jeszcze 'nie widział'.)\n",
        "*   Zastosujemy różne funkcje aktywacji\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-TRpHWUEhE2",
        "colab_type": "text"
      },
      "source": [
        "*   Warstwa ukryta musi mieć liczbę neuronów zgodną z liczbą danych wejściowych??? Macierz o zgodnych rozmiarach, np. próbka ma 2 cechy (czyli macierz 1x**2**), więc przy 2 neuronach ukrytych mamy macierz wag tych cech **2**x2. Wyboldowane wymiary muszą być ze sobą zgodne!\n",
        "*   Liczba neuronów w warstwie wejściowej jest zdeterminowana przez wymiar naszych danych, podobnie liczba neuronów w warstwie wyjściowej jest zdeterminowana przez liczbę naszych klas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3zojsdectdS",
        "colab_type": "text"
      },
      "source": [
        "Gradient funkcji w punkcie - kierunek, w którym funkcja rośnie najszybciej\n",
        "\n",
        "Dlatego wagi aktualizujemy w kierunku przeciwnym do gradientu, funkcja będzie zbliżać się do wartości minimalnej\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTT54UP_fgsu",
        "colab_type": "text"
      },
      "source": [
        "## Wzór na aktualizację wag: \n",
        "\n",
        "$*w_i = w_i - \\text{learning_rate} * \\frac{\\partial L}{\\partial w_i}$\n",
        "\n",
        "$\\frac{\\partial L}{\\partial w_i}$ - pochodna funkcji straty po danej wadze\n",
        "\n",
        "odejmujemy wartość pochodnej cząstkowej, po której aktualizujemy wagę, bo poruszamy się w przeciwnym kierunku, niż gradient\n",
        "\n",
        "$\\text{learning_rate}$ - pokazuje jak szybko sieć ma się uczyć"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyZIWgj0mfHf",
        "colab_type": "text"
      },
      "source": [
        "## Implementacja sieci neuronowej - czyli jak to działa"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eq-FbBR6g6fY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# x1- ilość odwiedzin na stronie\n",
        "# x2 - czas spędzony na stronie \n",
        "# y_pred - całkowity wydatek użytkownika"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_t_WNYN_nIC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# np.random.seed(0)\n",
        "\n",
        "X = np.array([[1.,0.7]])\n",
        "y_true=np.array([1.80])\n",
        "\n",
        "# wagi - losowe wartości z rozkładu normalnego blisko 0\n",
        "def initialize_parameters(n_x,n_h,n_y):\n",
        "\n",
        "    W1 = np.random.randn(n_x,n_h) \n",
        "# ???????\n",
        "# liczba danych wejściowych x iczba neuronów w warstwie ukrytej\n",
        "    W2 = np.random.randn(n_h,n_y)\n",
        "# l. neuronów x wyjście\n",
        "    return W1,W2\n",
        "\n",
        "def forward_propagation(X,W1,W2):\n",
        "# zasilenie sieci = propagacja w przód\n",
        "    H = np.dot(X,W1)\n",
        "    y_pred = np.dot(H,W2)\n",
        "    return H,y_pred\n",
        "\n",
        "def calculate_error(y_true,y_pred):\n",
        "    return y_pred-y_true\n",
        "\n",
        "def backpropagation(X,W1,W2,learning_rate=0.01,iters=1000,precision=0.0000001):\n",
        "# propagacja wsteczna - zaczynamy wagi aktualizować od końca,\n",
        "# wracając do początku sieci neuronowej\n",
        "    H,y_pred = forward_propagation(X,W1,W2)\n",
        "    \n",
        "    for i in range(iters):\n",
        "        error = calculate_error(y_true,y_pred)\n",
        "        W2 = W2 - learning_rate * error * H.T\n",
        "        W1 = W1 - learning_rate * error * X.T * W2.T\n",
        "\n",
        "        _, y_pred = forward_propagation(X,W1,W2)\n",
        "\n",
        "        print('Iter no. {}, y_pred: {}, error: {}'.format(i,y_pred[0][0],calculate_error(y_true,y_pred)[0][0]))\n",
        "\n",
        "        if abs(error)<precision:\n",
        "            break\n",
        "    return W1,W2\n",
        "\n",
        "def predict(X,W1,W2):\n",
        "    _,y_pred = forward_propagation(X,W1,W2)\n",
        "    return y_pred\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjYlFO0S0S_w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model():\n",
        "    \n",
        "    # inicjalizacja wag\n",
        "    W1,W2 = initialize_parameters(2,2,1)\n",
        "    \n",
        "    #propagacja wsteczna\n",
        "    W1,W2 = backpropagation(X,W1,W2)\n",
        "\n",
        "    model = {'W1':W1,'W2':W2}\n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvhIfz3E0X8q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bf477695-7567-4027-a11a-df077a7db15f"
      },
      "source": [
        "build_model()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iter no. 0, y_pred: 2.5102903258413267, error: 0.7102903258413267\n",
            "Iter no. 1, y_pred: 2.3942128886202894, error: 0.5942128886202893\n",
            "Iter no. 2, y_pred: 2.2975216051794445, error: 0.49752160517944444\n",
            "Iter no. 3, y_pred: 2.2168494026065098, error: 0.4168494026065097\n",
            "Iter no. 4, y_pred: 2.1494544326841285, error: 0.34945443268412846\n",
            "Iter no. 5, y_pred: 2.09309139796454, error: 0.29309139796453976\n",
            "Iter no. 6, y_pred: 2.045913194338284, error: 0.24591319433828374\n",
            "Iter no. 7, y_pred: 2.006394603914757, error: 0.20639460391475706\n",
            "Iter no. 8, y_pred: 1.9732723398847796, error: 0.17327233988477952\n",
            "Iter no. 9, y_pred: 1.9454974293328586, error: 0.14549742933285859\n",
            "Iter no. 10, y_pred: 1.9221970490121407, error: 0.12219704901214068\n",
            "Iter no. 11, y_pred: 1.902643701719494, error: 0.10264370171949388\n",
            "Iter no. 12, y_pred: 1.8862301600890445, error: 0.0862301600890445\n",
            "Iter no. 13, y_pred: 1.8724489879378585, error: 0.07244898793785848\n",
            "Iter no. 14, y_pred: 1.8608757266090086, error: 0.06087572660900853\n",
            "Iter no. 15, y_pred: 1.851155037689987, error: 0.05115503768998697\n",
            "Iter no. 16, y_pred: 1.8429892457536492, error: 0.04298924575364915\n",
            "Iter no. 17, y_pred: 1.8361288400685845, error: 0.03612884006858441\n",
            "Iter no. 18, y_pred: 1.830364582659354, error: 0.030364582659353934\n",
            "Iter no. 19, y_pred: 1.825520938717995, error: 0.02552093871799488\n",
            "Iter no. 20, y_pred: 1.8214505991760421, error: 0.021450599176042084\n",
            "Iter no. 21, y_pred: 1.818029907834708, error: 0.018029907834707926\n",
            "Iter no. 22, y_pred: 1.815155039439912, error: 0.015155039439912033\n",
            "Iter no. 23, y_pred: 1.8127388024133455, error: 0.012738802413345462\n",
            "Iter no. 24, y_pred: 1.8107079620584288, error: 0.010707962058428722\n",
            "Iter no. 25, y_pred: 1.8090009980466029, error: 0.009000998046602815\n",
            "Iter no. 26, y_pred: 1.8075662246936677, error: 0.007566224693667634\n",
            "Iter no. 27, y_pred: 1.8063602146071638, error: 0.006360214607163739\n",
            "Iter no. 28, y_pred: 1.8053464762307057, error: 0.00534647623070561\n",
            "Iter no. 29, y_pred: 1.8044943440297625, error: 0.004494344029762454\n",
            "Iter no. 30, y_pred: 1.8037780468728388, error: 0.0037780468728387806\n",
            "Iter no. 31, y_pred: 1.8031759258166429, error: 0.003175925816642833\n",
            "Iter no. 32, y_pred: 1.802669777208457, error: 0.002669777208456958\n",
            "Iter no. 33, y_pred: 1.8022443009393343, error: 0.002244300939334254\n",
            "Iter no. 34, y_pred: 1.8018866369532347, error: 0.001886636953234655\n",
            "Iter no. 35, y_pred: 1.8015859758503021, error: 0.0015859758503020682\n",
            "Iter no. 36, y_pred: 1.801333231708, error: 0.0013332317079999267\n",
            "Iter no. 37, y_pred: 1.8011207671566751, error: 0.0011207671566750843\n",
            "Iter no. 38, y_pred: 1.8009421623481598, error: 0.0009421623481598029\n",
            "Iter no. 39, y_pred: 1.8007920207985881, error: 0.0007920207985880889\n",
            "Iter no. 40, y_pred: 1.800665806212181, error: 0.0006658062121809305\n",
            "Iter no. 41, y_pred: 1.8005597053369513, error: 0.0005597053369512661\n",
            "Iter no. 42, y_pred: 1.8004705126954708, error: 0.00047051269547071506\n",
            "Iter no. 43, y_pred: 1.8003955336987736, error: 0.0003955336987735425\n",
            "Iter no. 44, y_pred: 1.8003325032096997, error: 0.00033250320969968605\n",
            "Iter no. 45, y_pred: 1.8002795170907322, error: 0.0002795170907321509\n",
            "Iter no. 46, y_pred: 1.8002349746650634, error: 0.00023497466506339215\n",
            "Iter no. 47, y_pred: 1.800197530350339, error: 0.00019753035033898136\n",
            "Iter no. 48, y_pred: 1.8001660530022807, error: 0.000166053002280675\n",
            "Iter no. 49, y_pred: 1.8001395917388776, error: 0.0001395917388775647\n",
            "Iter no. 50, y_pred: 1.800117347211875, error: 0.0001173472118749519\n",
            "Iter no. 51, y_pred: 1.8000986474571694, error: 9.864745716936518e-05\n",
            "Iter no. 52, y_pred: 1.8000829275941674, error: 8.292759416739237e-05\n",
            "Iter no. 53, y_pred: 1.8000697127605627, error: 6.971276056266795e-05\n",
            "Iter no. 54, y_pred: 1.8000586037668431, error: 5.860376684307944e-05\n",
            "Iter no. 55, y_pred: 1.8000492650370332, error: 4.926503703317486e-05\n",
            "Iter no. 56, y_pred: 1.800041414471266, error: 4.141447126593256e-05\n",
            "Iter no. 57, y_pred: 1.800034814923912, error: 3.481492391199659e-05\n",
            "Iter no. 58, y_pred: 1.8000292670397764, error: 2.926703977634837e-05\n",
            "Iter no. 59, y_pred: 1.8000246032319254, error: 2.460323192532421e-05\n",
            "Iter no. 60, y_pred: 1.8000206826192113, error: 2.0682619211287445e-05\n",
            "Iter no. 61, y_pred: 1.8000173867705427, error: 1.738677054263782e-05\n",
            "Iter no. 62, y_pred: 1.8000146161273451, error: 1.461612734510176e-05\n",
            "Iter no. 63, y_pred: 1.8000122869961293, error: 1.228699612920714e-05\n",
            "Iter no. 64, y_pred: 1.8000103290203033, error: 1.0329020303290193e-05\n",
            "Iter no. 65, y_pred: 1.8000086830548843, error: 8.683054884217611e-06\n",
            "Iter no. 66, y_pred: 1.8000072993798737, error: 7.299379873648704e-06\n",
            "Iter no. 67, y_pred: 1.8000061361983457, error: 6.136198345663146e-06\n",
            "Iter no. 68, y_pred: 1.8000051583738697, error: 5.158373869607047e-06\n",
            "Iter no. 69, y_pred: 1.8000043363691405, error: 4.336369140434115e-06\n",
            "Iter no. 70, y_pred: 1.800003645353729, error: 3.6453537288760884e-06\n",
            "Iter no. 71, y_pred: 1.800003064454025, error: 3.0644540249813446e-06\n",
            "Iter no. 72, y_pred: 1.8000025761227043, error: 2.576122704267547e-06\n",
            "Iter no. 73, y_pred: 1.8000021656086718, error: 2.165608671722552e-06\n",
            "Iter no. 74, y_pred: 1.800001820511469, error: 1.8205114689084922e-06\n",
            "Iter no. 75, y_pred: 1.8000015304066976, error: 1.5304066975918573e-06\n",
            "Iter no. 76, y_pred: 1.8000012865311237, error: 1.2865311236343047e-06\n",
            "Iter no. 77, y_pred: 1.800001081517963, error: 1.0815179629641847e-06\n",
            "Iter no. 78, y_pred: 1.8000009091743556, error: 9.091743555789122e-07\n",
            "Iter no. 79, y_pred: 1.800000764294297, error: 7.642942969621203e-07\n",
            "Iter no. 80, y_pred: 1.8000006425013724, error: 6.425013723276862e-07\n",
            "Iter no. 81, y_pred: 1.8000005401165708, error: 5.401165708018851e-07\n",
            "Iter no. 82, y_pred: 1.8000004540471397, error: 4.540471396641266e-07\n",
            "Iter no. 83, y_pred: 1.8000003816931671, error: 3.8169316707303835e-07\n",
            "Iter no. 84, y_pred: 1.8000003208690507, error: 3.208690506628642e-07\n",
            "Iter no. 85, y_pred: 1.8000002697374646, error: 2.6973746458658354e-07\n",
            "Iter no. 86, y_pred: 1.8000002267538733, error: 2.2675387323367602e-07\n",
            "Iter no. 87, y_pred: 1.8000001906198646, error: 1.9061986455959357e-07\n",
            "Iter no. 88, y_pred: 1.8000001602439348, error: 1.6024393478808463e-07\n",
            "Iter no. 89, y_pred: 1.800000134708513, error: 1.3470851301100595e-07\n",
            "Iter no. 90, y_pred: 1.8000001132422492, error: 1.1324224913344949e-07\n",
            "Iter no. 91, y_pred: 1.8000000951967077, error: 9.519670762792032e-08\n",
            "Iter no. 92, y_pred: 1.800000080026786, error: 8.002678586471745e-08\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'W1': array([[1.66971948, 0.45438846],\n",
              "        [0.91270498, 2.27885507]]), 'W2': array([[ 1.7390372 ],\n",
              "        [-1.08059026]])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cE-ySU9aBM5d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}